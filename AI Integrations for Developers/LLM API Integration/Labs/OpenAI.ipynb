{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2wnFb_4aBpP"
      },
      "outputs": [],
      "source": [
        "!pip install -q openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfdUb5dL4Fpq"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "from pydantic import BaseModel\n",
        "\n",
        "def print_response(response):\n",
        "  print(f\"Response id: {response.id}\")\n",
        "  pprint(response.output)\n",
        "\n",
        "  print()\n",
        "  print(f\"{'-' * 20} [Text] {'-' * 20}\")\n",
        "  print(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvF32EasJUEv"
      },
      "outputs": [],
      "source": [
        "prompts = {\n",
        "    \"business_naming\": \"Give me top 3 ideas for naming my business. It's a software company that innovates in audio recording.\",\n",
        "    \"describe_ai\": \"Describe AI as if it were an animal.\",\n",
        "    \"essay_about_humanity\": \"Write a short essay (up to 5 sentences) about the history of mankind.\",\n",
        "    \"generate_character\": \"Generate a fictional character of an adorable but nerdy teenager.\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nplGB86mdeeq"
      },
      "source": [
        "## Basic usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5zSdzs8aYP7"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpOcGEoYbkPc"
      },
      "outputs": [],
      "source": [
        "simple_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=prompts[\"essay_about_humanity\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cqFM0nPbr1i",
        "outputId": "c9453d4c-3fe4-448c-e5b8-2351dadbfe50"
      },
      "outputs": [],
      "source": [
        "print_response(simple_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY6ISED2dadC"
      },
      "source": [
        "## Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VX41dn1FAlE"
      },
      "outputs": [],
      "source": [
        "low_reasoning_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=prompts[\"business_naming\"],\n",
        "    reasoning={\"effort\": \"low\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGw2odpPJgAb",
        "outputId": "eb72559b-7370-4c8f-e423-b23dbc5e8f6b"
      },
      "outputs": [],
      "source": [
        "print_response(low_reasoning_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7wTVJxZJc8S"
      },
      "outputs": [],
      "source": [
        "high_reasoning_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=prompts[\"business_naming\"],\n",
        "    reasoning={\"effort\": \"high\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhmatcDIJDLn",
        "outputId": "8bf473dd-f24b-41fa-abfa-8329e769324a"
      },
      "outputs": [],
      "source": [
        "print_response(high_reasoning_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTdQk8PXMgPy"
      },
      "source": [
        "## Temperature\n",
        "\n",
        "The GPT-5 models no longer support `temperature` so the next demonstrations will use an older model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nm-gnHSLpAC"
      },
      "outputs": [],
      "source": [
        "deterministic_response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=prompts[\"describe_ai\"],\n",
        "    temperature=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLurcSSIM37W",
        "outputId": "1292c5a7-097c-405b-8e9f-4c2db8ca1de4"
      },
      "outputs": [],
      "source": [
        "print_response(deterministic_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONuZWhd7M9C9"
      },
      "outputs": [],
      "source": [
        "creative_response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=prompts[\"describe_ai\"],\n",
        "    temperature=0.9\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZTkA8bqNAg9",
        "outputId": "7968346e-a371-405d-8ba1-e445b0fdfbb0"
      },
      "outputs": [],
      "source": [
        "print_response(creative_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUhB_kDNP6YE"
      },
      "source": [
        "## Multi-turn conversations\n",
        "\n",
        "This example includes `instructions` giving the model high-level guidance on how it should behave while generating a response.\n",
        "\n",
        "> **OpenAI:**\n",
        "> _\"Note that the `instructions` parameter only applies to the current response generation request. If you are managing conversation state with the `previous_response_id` parameter, the `instructions` used on previous turns will not be present in the context.\"_\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwxKCxKNPpCk"
      },
      "outputs": [],
      "source": [
        "first_turn_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=\"Generate a short role-play in no more than 5 sentences: manager and employee discussing performance issues.\",\n",
        "    instructions=\"The manager should talk like a pirate.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgvu6oJEQrYr",
        "outputId": "f21c681e-775a-4799-ae30-d0a2779260b7"
      },
      "outputs": [],
      "source": [
        "print_response(first_turn_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2LGxE_aRBW8"
      },
      "outputs": [],
      "source": [
        "second_turn_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=\"Keep the role-play going for another 7 sentences, but introduce a new development: the employee's wife enters the room dramatically and tells him that she's pregnant, leaving him genuinely surpirsed but at the same time desperately hoping to save his job because his family depends on it.\",\n",
        "    previous_response_id=first_turn_response.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWYWFfTWRWiH",
        "outputId": "442bef9a-9766-433c-9fa8-96ae46753667"
      },
      "outputs": [],
      "source": [
        "print_response(second_turn_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjlH03a9U33r"
      },
      "source": [
        "## Structured output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKDYJPPscw5l"
      },
      "outputs": [],
      "source": [
        "no_structure_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=prompts[\"generate_character\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRW7Nfspc3m9",
        "outputId": "f048fb26-205c-4788-a25f-88d78db481d7"
      },
      "outputs": [],
      "source": [
        "print_response(no_structure_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28GHDOl5aH9U"
      },
      "source": [
        "`Structured output` evolves from `JSON mode`, however it is no longer recommended to use the latter for a number of reasons.\n",
        "\n",
        "> **OpenAI:**\n",
        "> _When using JSON mode, you must always instruct the model to produce JSON via some message in the conversation, for example via your system message. If you don't include an explicit instruction to generate JSON, the model may generate an unending stream of whitespace and the request may run continually until it reaches the token limit._\n",
        "\n",
        "> **OpenAI:**\n",
        "> _JSON mode will not guarantee the output matches any specific schema, only that it is valid and parses without errors._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1fkpWC8U4NF"
      },
      "outputs": [],
      "source": [
        "diy_structured_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=prompts[\"generate_character\"],\n",
        "    text={\n",
        "        \"format\": {\n",
        "            \"type\": \"json_schema\",\n",
        "            \"name\": \"character\",\n",
        "            \"schema\": {\n",
        "              \"type\": \"object\",\n",
        "              \"properties\": {\n",
        "                  \"name\": {\"type\": \"string\", \"description\": \"The character's full name\"},\n",
        "                  \"age\": {\"type\": \"integer\", \"description\": \"The character's age\"},\n",
        "                  \"hobby\": {\"type\": \"string\", \"description\": \"The character's hobby\"}\n",
        "              },\n",
        "              \"required\": [\"name\", \"age\", \"hobby\"],\n",
        "              \"additionalProperties\": False,\n",
        "            },\n",
        "            \"strict\": True\n",
        "        }\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQrSZFghVRV_",
        "outputId": "70f5bb00-05aa-43a5-a0fb-dc3173454902"
      },
      "outputs": [],
      "source": [
        "print_response(diy_structured_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdSwHS70a2E1"
      },
      "outputs": [],
      "source": [
        "class Character(BaseModel):\n",
        "    name: str\n",
        "    age: int\n",
        "    hobby: str\n",
        "\n",
        "auto_structured_response = client.responses.parse(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=prompts[\"generate_character\"],\n",
        "    text_format=Character\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYM0x0vjcWM_",
        "outputId": "d606d9c8-e446-434f-cffc-3edc03ce3af5"
      },
      "outputs": [],
      "source": [
        "print_response(auto_structured_response)\n",
        "\n",
        "print()\n",
        "print(f\"Parsed output: {auto_structured_response.output_parsed}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ileeDKhbeg9A"
      },
      "source": [
        "## Conversations API\n",
        "\n",
        "While `responses` are saved for 30 days only, `conversations` are stored until deleted. [OpenAI: Data retention](https://developers.openai.com/api/docs/guides/your-data#storage-requirements-and-retention-controls-per-endpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKq_82Q7e8Of"
      },
      "outputs": [],
      "source": [
        "conversation = client.conversations.create()\n",
        "first_conversation_item = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=\"Which cuisine do you preferâ€”Italian or French?\",\n",
        "    conversation=conversation.id\n",
        ")\n",
        "second_conversation_item = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=\"And what do you think about the languages?\",\n",
        "    conversation=conversation.id\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgMfWBGXjCsW",
        "outputId": "ba9f2ae8-dc16-4c16-c9e3-d54ef35b98ec"
      },
      "outputs": [],
      "source": [
        "print(f\"Conversation id: {conversation.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ae7JvLJYffBW",
        "outputId": "3d6ad3b1-c88e-4198-81d5-401497d56039"
      },
      "outputs": [],
      "source": [
        "print_response(first_conversation_item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3xC4hi3fkzR",
        "outputId": "32268fdd-c190-4992-eee0-aeac54b074fc"
      },
      "outputs": [],
      "source": [
        "print_response(second_conversation_item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ6VSOtpfqmV",
        "outputId": "8b45bf2b-182d-46c5-f680-86908727862e"
      },
      "outputs": [],
      "source": [
        "all_conversation_items = client.conversations.items.list(conversation_id=conversation.id)\n",
        "pprint(all_conversation_items.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOcS5WSg3y1_"
      },
      "source": [
        "## Vision\n",
        "\n",
        "<img src=\"https://freerangestock.com/sample/88947/painter-working-in-studio.jpg\" />\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD0t-xfw30HP"
      },
      "outputs": [],
      "source": [
        "image_analysis_response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are an expert image analyst. Keep your answer concise and structured.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                { \"type\": \"input_text\", \"text\": \"Analyze this image and return a one-sentence summary followed by 5 key visible objects.\" },\n",
        "                { \"type\": \"input_image\", \"image_url\": \"https://freerangestock.com/sample/88947/painter-working-in-studio.jpg\" }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktGfo8Rq7bnP",
        "outputId": "8e2c9526-a274-471a-f10e-944a58f202d0"
      },
      "outputs": [],
      "source": [
        "print_response(image_analysis_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nplGB86mdeeq",
        "sY6ISED2dadC",
        "MTdQk8PXMgPy",
        "AUhB_kDNP6YE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
